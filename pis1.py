#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
app_vn_exec_detect_total.py
==========================
Dashboard T·ªìn kho (Executive ‚Äì Ti·∫øng Vi·ªát)

N√ÇNG C·∫§P (v3 - UX/Logic Search th√¥ng minh):
‚úî Search ‚ÄúGoogle-like‚Äù: t·ª± nh·∫≠n di·ªán SKU vs t·ª´ kh√≥a, h·ªó tr·ª£ nhi·ªÅu token, x·∫øp h·∫°ng k·∫øt qu·∫£ theo ƒëi·ªÉm ph√π h·ª£p
‚úî ∆Øu ti√™n kh·ªõp m√£ SKU ch√≠nh x√°c / b·∫Øt ƒë·∫ßu / ch·ª©a; sau ƒë√≥ m·ªõi ƒë·∫øn t√™n/spec
‚úî Query c√≥ th·ªÉ l√†: "PIS-ABC123", "ABC123", "van kh√≠", "abc 123 pisco"
‚úî N·∫øu ch·ªâ c√≥ 1 k·∫øt qu·∫£ -> hi·ªÉn th·ªã Summary Card tr∆∞·ªõc b·∫£ng
‚úî C√≥ ‚ÄúSearch presets‚Äù v√† ‚Äúl·ªçc nhi·ªÖu‚Äù (min qty, ch·ªâ hi·ªÉn th·ªã SKU c√≥ t·ªìn > 0 theo kho ch·ªçn)
‚úî T·ªëi ∆∞u UX sidebar: √≠t nh∆∞ng ƒë√∫ng vi·ªác
‚úî ·∫®n th√¥ng s·ªë k·ªπ thu·∫≠t g√¢y nhi·ªÖu (snapshot_id, confidence...) ra kh·ªèi UI ch√≠nh; ch·ªâ ƒë·ªÉ Audit

Ghi ch√∫:
- ∆Øu ti√™n ƒë·ªçc DB theo latest snapshot (inventory_snapshot). N·∫øu kh√¥ng c√≥ th√¨ fallback t·ª´ inventory_data.
"""

from __future__ import annotations
import json
import re
import time
import sys
import subprocess
import sqlite3
from datetime import datetime
from pathlib import Path
from io import BytesIO

import pandas as pd
import streamlit as st

from detect_total_row import split_total_row

# ===================== CONFIG =====================
st.set_page_config(
    page_title="Dashboard PISCO ‚Äì Executive",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>

/* ===== KPI TILE ‚Äì STREAMLIT SAFE ===== */
div[data-testid="stMarkdown"] .kpi-tile {
    background: #FFFFFF !important;
    border-radius: 14px !important;
    padding: 16px 12px !important;
    text-align: center !important;
    border: 1px solid #E5E7EB !important;
    box-shadow: 0 2px 6px rgba(15,23,42,0.08) !important;
}

div[data-testid="stMarkdown"] .kpi-tile.primary {
    background: linear-gradient(135deg, #1F4FD8, #1C46C7) !important;
    color: #FFFFFF !important;
    border: none !important;
}

div[data-testid="stMarkdown"] .kpi-tile .label {
    font-size: 12px !important;
    font-weight: 700 !important;
    color: #64748B !important;
}

div[data-testid="stMarkdown"] .kpi-tile.primary .label {
    color: #E0E7FF !important;
}

div[data-testid="stMarkdown"] .kpi-tile .value {
    font-size: 26px !important;
    font-weight: 800 !important;
    margin-top: 6px !important;
}

</style>
""", unsafe_allow_html=True)



BASE_DIR = Path(__file__).resolve().parent
EXPORT_DIR = Path("/data/exports")
EXPORT_DIR.mkdir(exist_ok=True)

DB_PATH = Path("/data/pisco_inventory.db")
PARQUET_LATEST = EXPORT_DIR / "inventory_latest.parquet"

STATUS_FILE = EXPORT_DIR / "update_status.json"

UPDATE_JOB = BASE_DIR / "update_inventory_v2.py"
 # False n·∫øu ch·ªâ mu·ªën reload cache (kh√¥ng ch·∫°y crawler)

# UX mode (gi·ªØ ƒë∆°n gi·∫£n, c√≥ th·ªÉ m·ªü r·ªông th√™m)
UX_MODE = "EXECUTIVE"  # EXECUTIVE | ANALYST

QTY_COLS = [
    "total_qty",
    "mindman_qty",
    "pisco_jp_qty",
    "pisco_kr_qty",
    "pisco_tw_qty",
    "totra_qty",
]

WAREHOUSE_LABEL = {
    "total_qty": "T·ªïng",
    "mindman_qty": "Mindman",
    "pisco_jp_qty": "NIHON PISCO",
    "pisco_kr_qty": "Pisco KR",
    "pisco_tw_qty": "Pisco TW",
    "totra_qty": "Totra",
}

DISPLAY_QTY_COLS = [
    "total_qty",
    "mindman_qty",
    "pisco_jp_qty",
    "pisco_kr_qty",
    "pisco_tw_qty",
    "totra_qty",
]

DISPLAY_COLS = [
    "product_code",
    "product_name",
    "spec",
] + DISPLAY_QTY_COLS

MEETING_MODE_DEFAULT = False  # True n·∫øu mu·ªën v√†o l√† ·∫©n sidebar lu√¥n

# ===================== HELPERS =====================
def section(title: str, icon: str = "", desc: str | None = None):
    st.markdown(
        f"""
        <div style="
            border:1px solid #E6E6E6;
            border-radius:10px;
            padding:16px;
            margin-top:18px;
            margin-bottom:18px;
            background-color:#FFFFFF;
        ">
            <h4 style="margin-bottom:6px;">{icon} {title}</h4>
            {f"<div style='color:#666; font-size:13px; margin-bottom:12px;'>{desc}</div>" if desc else ""}
        </div>
        """,
        unsafe_allow_html=True
    )


def fmt_int(x) -> str:
    try:
        if pd.isna(x):
            return "-"
        return f"{int(x):,}"
    except Exception:
        return "-"

def fmt_pct(x) -> str:
    try:
        return f"{float(x):.2f}%"
    except Exception:
        return "-"

def normalize_sku_text(s: str) -> str:
    """
    Chu·∫©n h√≥a SKU ƒë·ªÉ so kh·ªõp:
    - Uppercase
    - B·ªè ti·ªÅn t·ªë PIS-
    - B·ªè m·ªçi k√Ω t·ª± kh√¥ng ph·∫£i ch·ªØ + s·ªë
    """
    if not isinstance(s, str):
        return ""
    s = s.upper().strip()
    if s.startswith("PIS-"):
        s = s[4:]
    s = re.sub(r"[^A-Z0-9]", "", s)
    return s

def tokenize_query(q: str) -> list[str]:
    """
    Token h√≥a query ƒë·ªÉ search th√¥ng minh:
    - Chu·∫©n h√≥a v·ªÅ uppercase
    - T√°ch theo space / d·∫•u
    - B·ªè token qu√° ng·∫Øn (<=1) ƒë·ªÉ gi·∫£m nhi·ªÖu
    """
    if not isinstance(q, str):
        return []
    q = q.strip()
    if not q:
        return []
    # gi·ªØ l·∫°i c·∫£ d·∫°ng raw tokens (c√≥ th·ªÉ c√≥ d·∫•u -) v√† norm tokens (A-Z0-9)
    raw = re.split(r"[\s,;|/\\]+", q.upper())
    raw = [t.strip() for t in raw if t.strip()]
    # gi·∫£m nhi·ªÖu: b·ªè token 1 k√Ω t·ª± (tr·ª´ khi to√†n query ch·ªâ 1 token)
    if len(raw) > 1:
        raw = [t for t in raw if len(t) > 1]
    return raw

def looks_like_sku(q: str) -> bool:
    """
    Heuristic: query tr√¥ng gi·ªëng SKU n·∫øu:
    - sau normalize c√≤n >= 4 k√Ω t·ª±
    - v√† c√≥ ch·ªØ + s·ªë ho·∫∑c ƒë·ªô d√†i l·ªõn
    """
    n = normalize_sku_text(q)
    if len(n) < 4:
        return False
    has_alpha = bool(re.search(r"[A-Z]", n))
    has_digit = bool(re.search(r"\d", n))
    if has_alpha and has_digit:
        return True
    # SKU to√†n s·ªë d√†i ho·∫∑c to√†n ch·ªØ d√†i v·∫´n c√≥ th·ªÉ l√† SKU
    return len(n) >= 8

def normalize(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()

    for c in ["product_code", "product_name", "spec", "snapshot_id", "snapshot_at"]:
        if c not in out.columns:
            out[c] = ""
        out[c] = out[c].astype(str).fillna("").str.strip()

    for c in QTY_COLS + ["total_safe_qty", "shortage_qty"]:
        if c not in out.columns:
            out[c] = 0
        out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0).astype("int64")

    
    out["_snapshot_at_dt"] = pd.to_datetime(out["snapshot_at"], errors="coerce")
    return out



def db_table_exists(conn: sqlite3.Connection, table_name: str) -> bool:
    q = "SELECT name FROM sqlite_master WHERE type='table' AND name=?"
    cur = conn.execute(q, (table_name,))
    return cur.fetchone() is not None

def get_latest_snapshot_id(conn: sqlite3.Connection) -> tuple[str | None, str | None, str | None]:
    """
    Returns: (snapshot_id, snapshot_at, status)
    """
    if db_table_exists(conn, "inventory_snapshot"):
        try:
            row = conn.execute(
                """
                SELECT snapshot_id, snapshot_at, status
                FROM inventory_snapshot
                ORDER BY created_at DESC
                LIMIT 1
                """
            ).fetchone()
            if row:
                return row[0], row[1], row[2]
        except Exception:
            pass
    return None, None, None

def list_snapshots(conn: sqlite3.Connection) -> pd.DataFrame:
    """
    Return snapshots list with columns: snapshot_id, snapshot_at, status, created_at
    Prefers inventory_snapshot; fallback to distinct from inventory_data.
    """
    if db_table_exists(conn, "inventory_snapshot"):
        df = pd.read_sql(
            """
            SELECT snapshot_id, snapshot_at, status, created_at
            FROM inventory_snapshot
            ORDER BY created_at DESC
            """,
            conn
        )
        if not df.empty:
            return df

    if db_table_exists(conn, "inventory_data"):
        df = pd.read_sql(
            """
            SELECT snapshot_id, snapshot_at
            FROM inventory_data
            GROUP BY snapshot_id, snapshot_at
            ORDER BY snapshot_at DESC
            """,
            conn
        )
        if not df.empty:
            df["status"] = None
            df["created_at"] = None
            return df

    return pd.DataFrame(columns=["snapshot_id", "snapshot_at", "status", "created_at"])

def load_latest_data_from_db() -> tuple[pd.DataFrame | None, dict]:
    """
    Load latest snapshot dataset.
    meta: {snapshot_id, snapshot_at, status, source}
    """
    if not DB_PATH.exists():
        return None, {"source": "none"}

    conn = sqlite3.connect(DB_PATH)
    try:
        sid, sat, status = get_latest_snapshot_id(conn)

        if sid:
            df = pd.read_sql(
                "SELECT * FROM inventory_data WHERE snapshot_id = ?",
                conn,
                params=(sid,)
            )
            return df, {
                "snapshot_id": sid,
                "snapshot_at": sat,
                "status": status,
                "source": "db:inventory_snapshot"
            }

        # fallback: no snapshot table -> pick max snapshot_at from inventory_data
        df = pd.read_sql("SELECT * FROM inventory_data", conn)
        if df.empty:
            return None, {"source": "db:empty"}

        df = normalize(df)
        max_dt = df["_snapshot_at_dt"].max()
        if pd.isna(max_dt):
            df = df.sort_values("snapshot_at", ascending=False)
            sat = df["snapshot_at"].iloc[0]
        else:
            df = df[df["_snapshot_at_dt"] == max_dt]
            sat = df["snapshot_at"].iloc[0] if "snapshot_at" in df.columns and len(df) else str(max_dt)

        df = df.drop(columns=["_snapshot_at_dt"], errors="ignore")
        return df, {
            "snapshot_id": df["snapshot_id"].iloc[0] if "snapshot_id" in df.columns and len(df) else None,
            "snapshot_at": sat,
            "status": None,
            "source": "db:fallback_inventory_data"
        }
    finally:
        conn.close()

def load_data() -> tuple[pd.DataFrame | None, dict]:
    """
    Priority: DB latest snapshot -> Parquet latest -> None
    """
    df, meta = load_latest_data_from_db()
    if df is not None and not df.empty:
        return df, meta

    if PARQUET_LATEST.exists():
        try:
            return pd.read_parquet(PARQUET_LATEST), {"source": "parquet"}
        except Exception:
            pass

    return None, {"source": "none"}

def kpi_top_share(df: pd.DataFrame, qty_col: str, top_n: int) -> float:
    total = df[qty_col].sum()
    if total <= 0:
        return 0.0
    top_sum = df.sort_values(qty_col, ascending=False).head(top_n)[qty_col].sum()
    return float(top_sum / total * 100)

def kpi_sku_for_80(df: pd.DataFrame, qty_col: str) -> int:
    tmp = df.sort_values(qty_col, ascending=False).copy()
    total = tmp[qty_col].sum()
    if total <= 0:
        return 0
    tmp["cum"] = tmp[qty_col].cumsum() / total
    return int((tmp["cum"] <= 0.80).sum())

def build_compare(now_df: pd.DataFrame, old_df: pd.DataFrame, qty_col: str) -> pd.DataFrame:
    now = now_df[["product_code", "product_name", "spec", qty_col]].copy()
    old = old_df[["product_code", qty_col]].copy()

    now = now.rename(columns={qty_col: "qty_now"})
    old = old.rename(columns={qty_col: "qty_old"})

    merged = now.merge(old, on="product_code", how="left")
    merged["qty_old"] = pd.to_numeric(merged["qty_old"], errors="coerce").fillna(0).astype("int64")
    merged["qty_now"] = pd.to_numeric(merged["qty_now"], errors="coerce").fillna(0).astype("int64")
    merged["delta"] = merged["qty_now"] - merged["qty_old"]
    # th√™m % change ƒë·ªÉ l·ªçc nhi·ªÖu
    merged["delta_pct"] = merged.apply(
        lambda r: (r["delta"] / r["qty_old"] * 100) if r["qty_old"] > 0 else (100.0 if r["qty_now"] > 0 else 0.0),
        axis=1
    )
    return merged

def to_excel_bytes(sheets: dict[str, pd.DataFrame]) -> bytes:
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
        for name, df in sheets.items():
            df.to_excel(writer, index=False, sheet_name=name[:31])
    return buf.getvalue()

def read_update_status() -> dict | None:
    if not STATUS_FILE.exists():
        return None
    try:
        return json.loads(STATUS_FILE.read_text(encoding="utf-8"))
    except Exception:
        return None

# ===================== SMART SEARCH (CORE) =====================
def prepare_search_index(df: pd.DataFrame) -> pd.DataFrame:
    """
    T·∫°o c·ªôt index ph·ª•c v·ª• search nhanh v√† nh·∫•t qu√°n.
    """
    out = df.copy()
    out["_norm_code"] = out["product_code"].apply(normalize_sku_text)
    out["_norm_name"] = out["product_name"].apply(normalize_sku_text)
    out["_norm_spec"] = out["spec"].apply(normalize_sku_text)

    # raw uppercase (gi·ªØ kho·∫£ng tr·∫Øng) ƒë·ªÉ search ki·ªÉu contains t·ª´ kh√≥a m·ªÅm
    out["_up_name"] = out["product_name"].astype(str).fillna("").str.upper()
    out["_up_spec"] = out["spec"].astype(str).fillna("").str.upper()
    out["_up_code"] = out["product_code"].astype(str).fillna("").str.upper()
    return out

def score_row(
    norm_q: str,
    raw_tokens: list[str],
    row: pd.Series
) -> int:
    """
    Ch·∫•m ƒëi·ªÉm 1 d√≤ng theo query.
    ∆Øu ti√™n SKU code, sau ƒë√≥ ƒë·∫øn name/spec.
    """
    score = 0

    code_n = row.get("_norm_code", "")
    name_n = row.get("_norm_name", "")
    spec_n = row.get("_norm_spec", "")

    up_code = row.get("_up_code", "")
    up_name = row.get("_up_name", "")
    up_spec = row.get("_up_spec", "")

    # 1) ∆Øu ti√™n kh·ªõp CODE (SKU) - m·∫°nh nh·∫•t
    if norm_q:
        if code_n == norm_q:
            score += 1000
        elif code_n.startswith(norm_q):
            score += 650
        elif norm_q in code_n:
            score += 450

    # 2) Token matching (gi√∫p query d·∫°ng "abc 123 pisco" v·∫´n ra)
    #    - token match code m·∫°nh h∆°n name/spec
    for t in raw_tokens:
        tn = normalize_sku_text(t)
        if not tn:
            continue

        if tn and tn == code_n:
            score += 220
        elif tn and code_n.startswith(tn):
            score += 160
        elif tn and tn in code_n:
            score += 120

        # name/spec normalized (m·ª©c v·ª´a)
        if tn and tn in name_n:
            score += 55
        if tn and tn in spec_n:
            score += 45

        # raw keyword search (m·ªÅm, gi√∫p ti·∫øng Vi·ªát/ƒë·∫∑c tr∆∞ng)
        # d√πng token raw uppercase ƒë·ªÉ match tr·ª±c ti·∫øp
        if t and t in up_name:
            score += 18
        if t and t in up_spec:
            score += 12

    # 3) Bonus: n·∫øu query tr√¥ng gi·ªëng SKU, m√† code match m·∫°nh -> ƒë·∫©y l√™n
    if norm_q and looks_like_sku(norm_q):
        if code_n.startswith(norm_q):
            score += 80
        if code_n == norm_q:
            score += 120

    return int(score)

def smart_search(
    df_indexed: pd.DataFrame,
    query: str,
    limit: int = 300,
    min_score: int = 30
) -> pd.DataFrame:
    """
    Search th√¥ng minh:
    - N·∫øu query r·ªóng: return df tr·ªëng (caller s·∫Ω x·ª≠ l√Ω hi·ªÉn th·ªã all)
    - N·∫øu query gi·ªëng SKU: ∆∞u ti√™n l·ªçc nhanh b·∫±ng code tr∆∞·ªõc
    - Sau ƒë√≥ ch·∫•m ƒëi·ªÉm + sort theo score
    """
    q = (query or "").strip()
    if not q:
        return df_indexed.iloc[0:0].copy()

    raw_tokens = tokenize_query(q)
    norm_q = normalize_sku_text(q)

    # Fast filter (gi·∫£m dataset tr∆∞·ªõc khi score) ƒë·ªÉ ch·∫°y nhanh v·ªõi data l·ªõn
    # Rule:
    # - N·∫øu norm_q ƒë·ªß d√†i -> l·ªçc c√°c d√≤ng c√≥ code/name/spec ch·ª©a norm_q (normalized)
    # - N·∫øu kh√¥ng -> l·ªçc theo raw token contains trong up_name/up_spec/up_code
    if norm_q and len(norm_q) >= 4:
        mask = (
            df_indexed["_norm_code"].str.contains(norm_q, na=False)
            | df_indexed["_norm_name"].str.contains(norm_q, na=False)
            | df_indexed["_norm_spec"].str.contains(norm_q, na=False)
        )
        pre = df_indexed[mask].copy()
    else:
        # d√πng token raw uppercase
        if not raw_tokens:
            pre = df_indexed.copy()
        else:
            m = False
            for t in raw_tokens[:6]:
                t = t.strip().upper()
                if not t:
                    continue
                m = m | df_indexed["_up_code"].str.contains(t, na=False) \
                      | df_indexed["_up_name"].str.contains(t, na=False) \
                      | df_indexed["_up_spec"].str.contains(t, na=False)
            pre = df_indexed[m].copy() if isinstance(m, pd.Series) else df_indexed.copy()

    if pre.empty:
        return pre

    # Score
    pre["_score"] = pre.apply(lambda r: score_row(norm_q, raw_tokens, r), axis=1)
    pre = pre[pre["_score"] >= min_score].copy()
    if pre.empty:
        return pre

    # Sort: score desc, then selected inventory desc (if exists later), then code
    pre = pre.sort_values(["_score", "_norm_code"], ascending=[False, True])

    return pre.head(limit).copy()

def render_sku_summary_card(row: pd.Series, rename_map: dict) -> None:
    """
    Hi·ªÉn th·ªã 1 SKU d∆∞·ªõi d·∫°ng card (Executive-friendly) khi search ra 1 d√≤ng.
    """
    st.markdown("### ‚úÖ K·∫øt qu·∫£ (SKU)")
    c1, c2 = st.columns([3, 2])

    with c1:
        st.markdown(f"**M√£ SKU:** `{row.get('product_code','')}`")
        st.markdown(f"**T√™n:** {row.get('product_name','')}")
        if row.get("spec", ""):
            st.markdown(f"**Quy c√°ch:** {row.get('spec','')}")
    with c2:
        # mini KPI theo kho
        st.markdown("**T·ªìn kho theo ƒë·ªãa ƒëi·ªÉm**")
        for k in QTY_COLS:
            st.write(f"- {rename_map.get(k, k)}: **{fmt_int(row.get(k, 0))}**")

# ===================== GLOBAL HEADER + UPDATE =====================
st.title("üìä Dashboard PISCO ‚Äì Executive")

col_u1, col_u2 = st.columns([1, 4])

if "is_updating" not in st.session_state:
    st.session_state["is_updating"] = False

with col_u1:
    clicked = st.button(
        "‚è≥ ƒêang c·∫≠p nh·∫≠t..." if st.session_state["is_updating"] else "üîÑ C·∫≠p nh·∫≠t d·ªØ li·ªáu",
        use_container_width=True,
        disabled=st.session_state["is_updating"]
    )

    if clicked:
        st.session_state["is_updating"] = True

        # ghi tr·∫°ng th√°i ngay ƒë·ªÉ tr√°nh click 2 l·∫ßn
        STATUS_FILE.write_text(
            json.dumps({
                "ts": datetime.now().isoformat(timespec="seconds"),
                "state": "running",
                "message": "Kh·ªüi ƒë·ªông job c·∫≠p nh·∫≠t",
                "progress": 0
            }),
            encoding="utf-8"
        )

        subprocess.Popen(
            [sys.executable, str(UPDATE_JOB)],
            cwd=str(BASE_DIR),
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )

        st.rerun()

# ===== REALTIME STATUS (POLLING) =====
status = read_update_status()

# ===================== GLOBAL UPDATE GUARD =====================
if status and status.get("state") == "running":
    st.markdown("---")
    st.subheader("‚è≥ H·ªá th·ªëng ƒëang c·∫≠p nh·∫≠t d·ªØ li·ªáu")
    st.info(
        "Qu√° tr√¨nh c·∫≠p nh·∫≠t ƒëang ch·∫°y ·ªü n·ªÅn.\n\n"
        "üîí To√†n b·ªô ch·ª©c nƒÉng t·∫°m th·ªùi b·ªã kh√≥a ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu nh·∫•t qu√°n.\n\n"
        "Vui l√≤ng ch·ªù trong gi√¢y l√°t‚Ä¶"
    )

    prog = status.get("progress")
    if prog is not None:
        st.progress(int(prog))

    # Kho·∫£ng ƒë·ªám UX
    st.caption("‚è± Trang s·∫Ω t·ª± ƒë·ªông c·∫≠p nh·∫≠t khi ho√†n t·∫•t")

    time.sleep(20)
    st.rerun()


if status:
    state = status.get("state")
    msg = status.get("message", "")
    prog = status.get("progress")
    ts = status.get("ts", "")

    from datetime import datetime

    with col_u2:
        try:
            dt = datetime.fromisoformat(ts)
            st.caption("üïí **C·∫≠p nh·∫≠t l·∫ßn cu·ªëi**")
            st.markdown(
                f"""
                - **Ng√†y:** {dt.strftime('%d/%m/%Y')}
                - **Gi·ªù:** {dt.strftime('%H:%M:%S')}
                """)
        except Exception:
            st.caption(f"üïí Tr·∫°ng th√°i l√∫c {ts}")
        if prog is not None:
            st.progress(int(prog))

        if state == "running":
            st.info(f"‚è≥ ƒêang c·∫≠p nh·∫≠t: {msg}")
            if prog is not None:
                st.progress(int(prog))
            time.sleep(20)
            st.rerun()

        elif state == "ok":
            st.success(f"‚úÖ Ho√†n t·∫•t: {msg}")
            time.sleep(2)
            try:
                STATUS_FILE.unlink()
            except Exception:
                pass
            st.session_state["is_updating"] = False
            st.rerun()

        elif state == "error":
            st.error(f"‚ùå L·ªói: {msg}")
            try:
                STATUS_FILE.unlink()
            except Exception:
                pass
            st.session_state["is_updating"] = False


       
    

# ===================== SIDEBAR NAV =====================
if "meeting_mode" not in st.session_state:
    st.session_state["meeting_mode"] = MEETING_MODE_DEFAULT

if not st.session_state["meeting_mode"]:
    st.sidebar.header("üìå Ch·ª©c nƒÉng")

    page = st.sidebar.radio(
        "Ch·ªçn trang",
        options=[
            "üìä Ph√¢n t√≠ch t·ªìn kho",
            "üîç Tra c·ª©u d·ªØ li·ªáu",
        ],
        index=1,
        key="page_nav"
    )

    st.sidebar.divider()
    st.sidebar.header("‚öôÔ∏è T√πy ch·ªçn")

    warehouse_options = list(WAREHOUSE_LABEL.keys())

    default_wh = (
        warehouse_options.index("pisco_jp_qty")
        if "pisco_jp_qty" in warehouse_options
        else 0
    )

    qty_col = st.sidebar.selectbox(
        "Ch·ªçn kho / ƒë·ªãa ƒëi·ªÉm",
        options=warehouse_options,
        index=default_wh,
        format_func=lambda x: WAREHOUSE_LABEL[x],
        key="select_warehouse"
    )

    st.caption(f"üîé ƒêang xem t·ªìn kho: **{WAREHOUSE_LABEL[qty_col]}**")
    if page == "üîç Tra c·ª©u t·ªìn kho chi ti·∫øt":
        st.sidebar.divider()
        st.sidebar.header("üßπ L·ªçc")
        filter_positive_only = st.sidebar.checkbox(
            f"Ch·ªâ SKU c√≥ t·ªìn > 0 ({WAREHOUSE_LABEL[qty_col]})",
            value=True
        )
        min_qty = st.sidebar.number_input(
            f"Ng∆∞·ª°ng t·ªìn t·ªëi thi·ªÉu ({WAREHOUSE_LABEL[qty_col]})",
            min_value=0,
            value=0,
            step=10
        )
else:
    # Meeting mode defaults
    page = "üîç Tra c·ª©u t·ªìn kho chi ti·∫øt"
    qty_col = "total_qty"
    

# ===== DEFAULT FILTER VALUES (ALWAYS DEFINED) =====
filter_positive_only = True
min_qty = 0

# ===================== LOAD + CLEAN DATA (ONE TIME) =====================
raw, meta_src = load_data()
if raw is None or raw.empty:
    st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu. H√£y b·∫•m ‚ÄúC·∫≠p nh·∫≠t d·ªØ li·ªáu‚Äù ƒë·ªÉ ch·∫°y job/crawler.")
    st.stop()

raw = normalize(raw)

clean_df, total_row, meta_total = split_total_row(
    raw,
    qty_cols=QTY_COLS,
    code_col="product_code",
    name_col="product_name",
    spec_col="spec",
    tolerance=0,
    min_confidence=0.80,
    last_k_rows=8,
)

snapshot_at_display = meta_src.get("snapshot_at") or (clean_df["snapshot_at"].iloc[0] if "snapshot_at" in clean_df.columns else "-")
status_display = meta_src.get("status")

# Header caption (Executive-friendly)
st.caption(
    f"üìÖ D·ªØ li·ªáu ng√†y: {snapshot_at_display}"
    + (f" | üü¢ Tr·∫°ng th√°i: {status_display}" if status_display else "")
    + f" | ‚è± Hi·ªÉn th·ªã l√∫c: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}"
)



# ===================== PAGE: ANALYSIS =====================
if page == "üìä Ph√¢n t√≠ch t·ªìn kho":
    st.subheader("üìå Ch·ªâ s·ªë t·ªïng quan (Executive)")

    total_all = int(clean_df["total_qty"].sum())
    selected_total = int(clean_df[qty_col].sum())
    pct_share = (selected_total / total_all * 100) if total_all > 0 else 0.0
    top10_share = kpi_top_share(clean_df, qty_col, top_n=10)
    sku80 = kpi_sku_for_80(clean_df, qty_col)
    total_sku = clean_df["product_code"].nunique()

    # Executive KPI: gi·∫£m nhi·ªÖu
    if UX_MODE == "EXECUTIVE":
        k1, k2, k3 = st.columns(3)
        with k1:
            st.metric(f"T·ªïng t·ªìn kho ({WAREHOUSE_LABEL[qty_col]})", fmt_int(selected_total))
            st.caption("T·ªïng s·ªë l∆∞·ª£ng t·ªìn t·∫°i kho ƒëang ch·ªçn")

        with k2:
            st.metric("SKU t·∫°o 80% t·ªìn kho", f"{sku80:,} / {total_sku:,}")
            st.caption("S·ªë SKU t·∫°o ra 80% t·ªìn kho (nh√≥m c·∫ßn t·∫≠p trung qu·∫£n l√Ω)")

        with k3:
            st.metric(f"T·ª∑ tr·ªçng {WAREHOUSE_LABEL[qty_col]} / T·ªïng", fmt_pct(pct_share))
            st.caption("Kho n√†y chi·∫øm bao nhi√™u % t·ªïng t·ªìn kho to√†n h·ªá th·ªëng")
    else:
        k1, k2, k3, k4 = st.columns(4)
        with k1:
            st.metric(f"T·ªïng t·ªìn kho ({WAREHOUSE_LABEL[qty_col]})", fmt_int(selected_total))
        with k2:
            st.metric(f"T·ª∑ tr·ªçng {WAREHOUSE_LABEL[qty_col]} / T·ªïng", fmt_pct(pct_share))
        with k3:
            st.metric("10 SKU l·ªõn nh·∫•t chi·∫øm", fmt_pct(top10_share))
        with k4:
            st.metric("SKU c·∫ßn qu·∫£n l√Ω ch√≠nh", f"{sku80:,} / {total_sku:,}")

    st.subheader("üìã Top 20 SKU t·ªìn kho cao nh·∫•t")
    top20_df = (
        clean_df.sort_values(qty_col, ascending=False)
        .head(20)[["product_code", "product_name", "spec", qty_col]]
        .rename(columns={qty_col: f"T·ªìn ({WAREHOUSE_LABEL[qty_col]})"})
    )

    # Executive caption: gi·∫£i th√≠ch ‚Äúv√¨ sao quan tr·ªçng‚Äù
    if selected_total > 0:
        top20_sum = int(clean_df.sort_values(qty_col, ascending=False).head(20)[qty_col].sum())
        share = (top20_sum / selected_total * 100) if selected_total else 0
        st.caption(f"20 SKU n√†y chi·∫øm kho·∫£ng {share:.1f}% t·ªìn kho kho ƒëang ch·ªçn. ƒê√¢y l√† nh√≥m n√™n ki·ªÉm so√°t v√≤ng quay v√† k·∫ø ho·∫°ch nh·∫≠p/x·∫£.")
    st.dataframe(top20_df, use_container_width=True, height=420)

    st.subheader("üîé So s√°nh v·ªõi qu√° kh·ª© (theo snapshot)")
    if not DB_PATH.exists():
        st.info("Ch∆∞a c√≥ DB ƒë·ªÉ so s√°nh snapshot.")
    else:
        conn = sqlite3.connect(DB_PATH)
        try:
            snaps = list_snapshots(conn)
            if snaps.empty or "snapshot_id" not in snaps.columns:
                st.info("Ch∆∞a c√≥ l·ªãch s·ª≠ snapshot.")
            else:
                snaps = snaps.copy()
                snaps["snapshot_at"] = snaps["snapshot_at"].astype(str)
                snaps["label"] = snaps["snapshot_at"].fillna("") + snaps["snapshot_id"].apply(lambda x: f"  (ID: {x})")

                current_sid = meta_src.get("snapshot_id") or (
                    clean_df["snapshot_id"].iloc[0] if "snapshot_id" in clean_df.columns and len(clean_df) else None
                )

                snap_options = snaps["label"].tolist()
                snap_map = dict(zip(snaps["label"], snaps["snapshot_id"]))
                snap_at_map = dict(zip(snaps["snapshot_id"], snaps["snapshot_at"]))

                # default ch·ªçn snapshot g·∫ßn nh·∫•t tr∆∞·ªõc ƒë√≥ (kh√°c current)
                default_idx = 0
                if current_sid:
                    idxs = snaps.index[snaps["snapshot_id"] == current_sid].tolist()
                    if idxs:
                        i = idxs[0]
                        if i + 1 < len(snaps):
                            default_idx = i + 1

                compare_label = st.selectbox(
                    "Ch·ªçn snapshot qu√° kh·ª©",
                    options=snap_options,
                    index=min(default_idx, len(snap_options) - 1),
                    key="compare_snapshot_select"
                )
                compare_sid = snap_map.get(compare_label)

                if compare_sid == current_sid:
                    st.warning("B·∫°n ƒëang ch·ªçn snapshot hi·ªán t·∫°i. H√£y ch·ªçn snapshot kh√°c.")
                else:
                    old_df = pd.read_sql(
                        "SELECT * FROM inventory_data WHERE snapshot_id = ?",
                        conn,
                        params=(compare_sid,)
                    )
                    if old_df.empty:
                        st.info("Snapshot qu√° kh·ª© kh√¥ng c√≥ d·ªØ li·ªáu.")
                    else:
                        old_df = normalize(old_df)
                        old_clean, _, _ = split_total_row(
                            old_df,
                            qty_cols=QTY_COLS,
                            code_col="product_code",
                            name_col="product_name",
                            spec_col="spec",
                            tolerance=0,
                            min_confidence=0.80,
                            last_k_rows=8,
                        )

                        cmp_df = build_compare(clean_df, old_clean, qty_col)

                        now_sum = int(clean_df[qty_col].sum())
                        old_sum = int(old_clean[qty_col].sum())
                        delta_sum = now_sum - old_sum

                        c1, c2, c3 = st.columns(3)
                        with c1: st.metric("T·ªìn hi·ªán t·∫°i", fmt_int(now_sum))
                        with c2: st.metric("T·ªìn qu√° kh·ª©", fmt_int(old_sum))
                        with c3: st.metric("Ch√™nh l·ªách", fmt_int(delta_sum))

                        # L·ªçc nhi·ªÖu bi·∫øn ƒë·ªông nh·ªè (Executive)
                       

                        with st.expander("üßπ L·ªçc nhi·ªÖu bi·∫øn ƒë·ªông (Executive)", expanded=False):
                            delta_abs_min = st.number_input("Ng∆∞·ª°ng |delta| t·ªëi thi·ªÉu", min_value=0, value=50, step=10)
                            delta_pct_min = st.number_input("Ng∆∞·ª°ng |delta%| t·ªëi thi·ªÉu", min_value=0.0, value=10.0, step=1.0)
                        filtered_cmp = cmp_df[
                            (cmp_df["delta"].abs() >= int(delta_abs_min)) | (cmp_df["delta_pct"].abs() >= float(delta_pct_min))
                        ].copy()

                        inc = filtered_cmp.sort_values("delta", ascending=False).head(15)
                        dec = filtered_cmp.sort_values("delta", ascending=True).head(15)

                        left, right = st.columns(2)
                        with left:
                            st.markdown("**üìà Top tƒÉng t·ªìn kho**")
                            st.dataframe(
                                inc[["product_code", "product_name", "spec", "qty_old", "qty_now", "delta", "delta_pct"]],
                                use_container_width=True,
                                height=380
                            )
                        with right:
                            st.markdown("**üìâ Top gi·∫£m t·ªìn kho**")
                            st.dataframe(
                                dec[["product_code", "product_name", "spec", "qty_old", "qty_now", "delta", "delta_pct"]],
                                use_container_width=True,
                                height=380
                            )
        finally:
            conn.close()

    st.subheader("‚¨áÔ∏è Xu·∫•t b√°o c√°o Excel")
    overview_df = pd.DataFrame([{
        "Snapshot": snapshot_at_display,
        "Kho ƒëang ch·ªçn": WAREHOUSE_LABEL[qty_col],
        "T·ªìn kho kho ch·ªçn": int(clean_df[qty_col].sum()),
        "% kho / t·ªïng": round((clean_df[qty_col].sum() / clean_df["total_qty"].sum() * 100) if clean_df["total_qty"].sum() else 0, 2),
        "Top 10 chi·∫øm (%)": round(kpi_top_share(clean_df, qty_col, 10), 2),
        "SKU t·∫°o 80% t·ªìn kho": kpi_sku_for_80(clean_df, qty_col),
        "Ngu·ªìn": meta_src.get("source"),
    }])

    xlsx_bytes = to_excel_bytes({
        "Tong_quan": overview_df,
        "Top20_SKU": top20_df,
    })

    section(
        title="Xu·∫•t d·ªØ li·ªáu",
        icon="‚¨áÔ∏è",
        desc="T·∫£i file Excel ƒë√∫ng theo d·ªØ li·ªáu ƒëang hi·ªÉn th·ªã tr√™n m√†n h√¨nh"
    )

    st.download_button(
        label="üì• T·∫£i Excel (T·ªïng quan + Top20)",
        data=xlsx_bytes,
        file_name=f"bao_cao_ton_kho_{WAREHOUSE_LABEL[qty_col]}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True
    )

    st.subheader("‚öñÔ∏è So s√°nh 2 kho song song")

    c1, c2 = st.columns(2)
    with c1:
        wh_left = st.selectbox(
            "Kho A",
            options=list(WAREHOUSE_LABEL.keys()),
            format_func=lambda x: WAREHOUSE_LABEL[x],
            key="compare_wh_left"
        )

    with c2:
        wh_right = st.selectbox(
            "Kho B",
            options=list(WAREHOUSE_LABEL.keys()),
            format_func=lambda x: WAREHOUSE_LABEL[x],
            index=1,
            key="compare_wh_right"
        )
    compare_df = clean_df[
        ["product_code", "product_name", "spec", wh_left, wh_right]
    ].copy()

    compare_df["Ch√™nh l·ªách"] = compare_df[wh_left] - compare_df[wh_right]

    compare_df = compare_df.rename(columns={
        "product_code": "M√£ SKU",
        "product_name": "T√™n s·∫£n ph·∫©m",
        "spec": "Quy c√°ch",
        wh_left: WAREHOUSE_LABEL[wh_left],
        wh_right: WAREHOUSE_LABEL[wh_right],
    })

    compare_df = compare_df[
        (compare_df[WAREHOUSE_LABEL[wh_left]] +
        compare_df[WAREHOUSE_LABEL[wh_right]]) > 0
    ]

    st.dataframe(
        compare_df.sort_values("Ch√™nh l·ªách", ascending=False),
        use_container_width=True,
        height=520
    )
# ===================== PAGE: CRAWLER DATA BROWSER =====================
else:
    # ===== MEETING MODE TOGGLE =====
    c1, c2 = st.columns([6, 1])
    with c1:
        st.subheader("üîç Tra c·ª©u t·ªìn kho chi ti·∫øt")
    with c2:
        if st.button("üé§ Meeting Mode" if not st.session_state["meeting_mode"] else "‚ùå Tho√°t h·ªçp"):
            st.session_state["meeting_mode"] = not st.session_state["meeting_mode"]
            st.rerun()

    

    display_cols = ["product_code", "product_name", "spec"] + QTY_COLS
    browser_df = clean_df[display_cols].copy()

    rename_map = {
        "product_code": "M√£ SKU",
        "product_name": "T√™n s·∫£n ph·∫©m",
        "spec": "Quy c√°ch",
        "total_qty": "T·ªïng",
        "mindman_qty": "Mindman",
        "pisco_jp_qty": "NIHON PISCO",
        "pisco_kr_qty": "Pisco KR",
        "pisco_tw_qty": "Pisco TW",
        "totra_qty": "Totra",
    }

    # ===== SEARCH INPUT (MULTI-SKU) =====

    
    search_block = st.text_area(
        "",
        placeholder="Nh·∫≠p m√£ ho·∫∑c t√™n ƒë·ªÉ t√¨m ki·∫øm\nC√°ch nhau b·∫±ng d·∫•u ph·∫©y ho·∫∑c xu·ªëng h√†ng",
        height=90,
        label_visibility="collapsed"
    )

# ===== CONTROL: WHEN TO SHOW TABLE =====
    show_table = False

    # C√≥ search text
    if search_block.strip():
        show_table = True
    # ===== FILTER =====
    if filter_positive_only:
        browser_df = browser_df[browser_df[qty_col] > 0].copy()
    if min_qty > 0:
        browser_df = browser_df[browser_df[qty_col] >= int(min_qty)].copy()

    indexed = prepare_search_index(browser_df)

    # ===== MULTI QUERY PARSE + LIMIT =====
    queries = []
    if search_block.strip():
        raw_lines = re.split(r"[\n,]+", search_block)
        queries = [q.strip() for q in raw_lines if q.strip()]
        if len(queries) > 50:
            st.info("B·∫°n d√°n nhi·ªÅu h∆°n 50 d√≤ng. H·ªá th·ªëng s·∫Ω x·ª≠ l√Ω 50 d√≤ng ƒë·∫ßu ƒë·ªÉ ƒë·∫£m b·∫£o t·ªëc ƒë·ªô.")
            queries = queries[:50]

    if queries:
        frames = []
        for q in queries:
            r = smart_search(indexed, q, limit=300, min_score=30)
            frames.append(r)
        tmp = pd.concat(frames, ignore_index=True)

        # gi·ªØ SKU c√≥ score cao nh·∫•t
        if "_score" in tmp.columns:
            tmp = tmp.sort_values("_score", ascending=False)

        result = tmp.drop_duplicates(subset=["product_code"], keep="first").copy()
    else:
        result = indexed.copy()

    if result.empty:
        st.warning("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p.")
        st.stop()

    # ===== SUM ROW (tr√™n raw columns) =====
    sum_row = {c: int(result[c].sum()) for c in QTY_COLS}
    sum_row.update({"product_code": "T·ªîNG C·ªòNG", "product_name": "", "spec": ""})

    # ===== HI·ªÇN TH·ªä: rename qty_col ‚Üí t·ªìn kho ƒëang ch·ªçn =====
    result_show = result.drop(
        columns=["_norm_code", "_norm_name", "_norm_spec", "_up_code", "_up_name", "_up_spec"],
        errors="ignore"
    ).copy()

    ordered_cols = ["product_code", "product_name", "spec", qty_col] + [c for c in QTY_COLS if c != qty_col]
    result_show = result_show[ordered_cols]

    qty_col_display = f"T·ªìn ({WAREHOUSE_LABEL[qty_col]})"
    result_show = result_show.rename(columns={qty_col: qty_col_display}).rename(columns=rename_map)

    # ===== HIGHLIGHT LOGIC (PH·∫¢I L√ÄM TR∆Ø·ªöC KHI st.dataframe) =====
    # Overstock
    top_pct = 0.10
    abs_threshold = 1000

    top_n = max(1, int(len(result_show) * top_pct))
    overstock_count = (
        result_show[qty_col_display] >= abs_threshold
    ).sum()

    shortage_count = (
        clean_df["shortage_qty"] > 0
    ).sum()

  

 # ===== FILTER HEADER (NUMERIC) =====
    numeric_cols = [
        c for c in result_show.columns
        if c not in ["M√£ SKU", "T√™n s·∫£n ph·∫©m", "Quy c√°ch"]
    ]
   
    with st.expander("üîß L·ªçc d·ªØ li·ªáu trong b·∫£ng", expanded=False):
        f1, f2, f3, f4 = st.columns([3, 2, 2, 2])

        with f1:
            filter_col = st.selectbox(
                "C·ªôt",
                options=numeric_cols,
                key="tbl_filter_col"
            )

        with f2:
            filter_op = st.selectbox(
                "ƒêi·ªÅu ki·ªán",
                options=[">", "<", ">=", "<=", "=", "Between"],
                key="tbl_filter_op"
            )

        with f3:
            filter_val1 = st.number_input(
                "Gi√° tr·ªã",
                value=0,
                key="tbl_filter_val1"
            )

        with f4:
            filter_val2 = st.number_input(
                "ƒê·∫øn",
                value=0,
                key="tbl_filter_val2"
            )

    # ===== APPLY FILTER =====
    filtered_show = result_show.copy()

    if filter_op == ">":
        filtered_show = filtered_show[filtered_show[filter_col] > filter_val1]

    elif filter_op == "<":
        filtered_show = filtered_show[filtered_show[filter_col] < filter_val1]

    elif filter_op == ">=":
        filtered_show = filtered_show[filtered_show[filter_col] >= filter_val1]

    elif filter_op == "<=":
        filtered_show = filtered_show[filtered_show[filter_col] <= filter_val1]

    elif filter_op == "=":
        filtered_show = filtered_show[filtered_show[filter_col] == filter_val1]

    elif filter_op == "Between":
        lo = min(filter_val1, filter_val2)
        hi = max(filter_val1, filter_val2)
        filtered_show = filtered_show[
            (filtered_show[filter_col] >= lo) &
            (filtered_show[filter_col] <= hi)
        ]
    
    # ===== SUMMARY (DYNAMIC - FOLLOW FILTERED DATA) =====
    if show_table:
        section(
            title="K·∫øt qu·∫£ t·ªìn kho (theo t√¨m ki·∫øm)",
            icon="üìå",
            desc="T·ªïng s·ªë l∆∞·ª£ng t·ªìn kho d·ª±a tr√™n k·∫øt qu·∫£ t√¨m ki·∫øm v√† b·ªô l·ªçc"
        )

        # X√°c ƒë·ªãnh l·∫°i c·ªôt t·ªìn kho ƒëang ch·ªçn
        qty_col_display = f"T·ªìn ({WAREHOUSE_LABEL[qty_col]})"

        summary_map = {}

        # 1. T·ªïng t·ªìn theo kho ƒëang ch·ªçn
        if qty_col_display in filtered_show.columns:
            summary_map[qty_col_display] = int(filtered_show[qty_col_display].sum())

        # 2. C√°c kho c√≤n l·∫°i
        for c in QTY_COLS:
            label = rename_map.get(c, c)
            if label in filtered_show.columns and label != qty_col_display:
                summary_map[label] = int(filtered_show[label].sum())

        # 3. Render summary bar
        cols = st.columns(len(summary_map))

        for i, (label, val) in enumerate(summary_map.items()):
            is_primary = (label == WAREHOUSE_LABEL[qty_col])
            tile_class = "kpi-tile primary" if is_primary else "kpi-tile"

            cols[i].markdown(
                f"""
                <div class="{tile_class}">
                    <div class="label">{label}</div>
                    <div class="value">{val:,}</div>
                </div>
                """,
                unsafe_allow_html=True
            )


    # ===== MAIN TABLE =====
    if show_table:
        st.caption(f"Hi·ªÉn th·ªã {len(filtered_show):,} SKU")

        left_info, right_info = st.columns([2.2, 1], gap="small")
        with left_info:
            st.success(f"‚úÖ {len(filtered_show):,} SKU")
        with right_info:
            st.caption("M·∫πo: click t√™n c·ªôt ƒë·ªÉ sort nhanh")
        st.subheader("üìã Danh s√°ch SKU ph√π h·ª£p")
        st.caption("Danh s√°ch chi ti·∫øt kh·ªõp v·ªõi k·∫øt qu·∫£ t·ªïng h·ª£p ph√≠a tr√™n")
        st.dataframe(
            filtered_show,
            use_container_width=True,
            height=460
        )
    


    


    # ===== EXPORT (Excel = ƒë√∫ng nh∆∞ m√†n h√¨nh + th√™m d√≤ng t·ªïng) =====
    export_df = filtered_show.copy()
    total_row_export = {c: "" for c in export_df.columns}
    total_row_export["Tr·∫°ng th√°i"] = ""
    total_row_export["M√£ SKU"] = "T·ªîNG C·ªòNG"
    total_row_export[qty_col_display] = int(result[qty_col].sum())

    # map c√°c kho c√≤n l·∫°i theo rename_map
    for c in QTY_COLS:
        label = rename_map.get(c, c)
        if label in export_df.columns and label != qty_col_display:
            total_row_export[label] = int(result[c].sum())

    export_df = pd.concat([export_df, pd.DataFrame([total_row_export])], ignore_index=True)

    xlsx_bytes = to_excel_bytes({"Crawler_Result": export_df})
    if show_table:
        section(
            title="Xu·∫•t d·ªØ li·ªáu",
            icon="‚¨áÔ∏è",
            desc="T·∫£i file Excel ƒë√∫ng theo d·ªØ li·ªáu ƒëang hi·ªÉn th·ªã tr√™n m√†n h√¨nh"
        )
        st.download_button(
            label="üì• T·∫£i Excel (ƒê√∫ng nh∆∞ m√†n h√¨nh)",
            data=xlsx_bytes,
            file_name=f"tra_cuu_crawler_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
